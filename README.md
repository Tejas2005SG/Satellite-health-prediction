# ğŸ›°ï¸ Satellite Health AI

AI-Powered Satellite Health Monitoring System built with Modal.com GPU training.

## ğŸ“‹ Overview

This project implements a complete AI pipeline for:
- **Real-time Health Monitoring**: Detect anomalies in satellite telemetry
- **Predictive Maintenance**: Forecast future failures before they happen

## ğŸ—ï¸ Architecture

```
Modal.com Cloud Infrastructure
â”œâ”€â”€ Volume: satellite-data-vol (10GB) - Datasets
â”œâ”€â”€ Volume: satellite-results-vol (10GB) - Models & Logs
â””â”€â”€ GPU Container (A100) - Training & Inference

Local Development
â”œâ”€â”€ modal/ - Deployment scripts
â”œâ”€â”€ src/ - Core modules
â”œâ”€â”€ tests/ - Empirical testing
â””â”€â”€ scripts/ - Automation
```

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Install dependencies
pip install -r requirements.txt

# Authenticate with Modal
modal token new

# Run setup
python scripts/setup.py
```

### 2. Download Datasets

```bash
# Download all datasets (NASA, ESA, NOAA)
python scripts/download_data.py all

# Or download individually
python scripts/download_data.py nasa
python scripts/download_data.py esa
python scripts/download_data.py noaa
```

### 3. Run Tests

```bash
# Setup verification
python tests/test_setup.py

# Data loading tests
python tests/test_data_loading.py

# Model architecture tests
python tests/test_models.py

# Full integration test
python tests/test_integration.py
```

### 4. Train Models

```bash
# Train all models (2-3 hours)
python scripts/run_training.py all

# Or train individually
modal run modal.train_anomaly
modal run modal.train_predictive
```

### 5. Run Inference

```bash
# Anomaly detection
modal run modal.inference::detect_anomalies

# Predictive maintenance
modal run modal.inference::predict_maintenance
```

## ğŸ“Š Datasets

- **NASA SMAP/MSL**: Real telemetry with expert-labeled anomalies (~500MB)
- **ESA OPS-SAT**: European Space Agency CubeSat data (~200MB)
- **NOAA Space Weather**: Solar flare and geomagnetic data (~100MB)

Total: ~800MB stored in Modal volumes

## ğŸ¤– Models

### 1. Anomaly Detection (LSTM Autoencoder)
- **Architecture**: LSTM encoder-decoder
- **Input**: 100-timestep sequences
- **Output**: Reconstruction error for anomaly detection
- **Expected F1**: 0.85-0.88

### 2. Predictive Maintenance (LSTM Forecaster)
- **Architecture**: Multi-layer LSTM
- **Input**: 100-timestep sequences
- **Output**: 20-step ahead predictions
- **Expected MAE**: <2.5Â°C

## ğŸ’° Cost Estimate

With $30 Modal credits:
- **Dataset download**: ~$0.75
- **Anomaly training**: ~$1.50 (45 min)
- **Predictive training**: ~$1.50 (45 min)
- **Total**: ~$4-5
- **Remaining**: ~$25-26 for experiments

## ğŸ“ Project Structure

```
satellite-health-ai/
â”œâ”€â”€ modal/
â”‚   â”œâ”€â”€ config.py              # App configuration
â”‚   â”œâ”€â”€ volumes.py             # Volume setup
â”‚   â”œâ”€â”€ download_datasets.py   # Data download
â”‚   â”œâ”€â”€ train_anomaly.py       # Anomaly training
â”‚   â”œâ”€â”€ train_predictive.py    # Predictive training
â”‚   â””â”€â”€ inference.py           # Inference functions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loaders.py         # Data loading
â”‚   â”‚   â””â”€â”€ preprocessors.py   # Data preprocessing
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ anomaly_detector.py
â”‚   â”‚   â””â”€â”€ predictive_model.py
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ metrics.py         # Evaluation metrics
â”‚       â””â”€â”€ logger.py          # Logging utilities
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_setup.py          # Setup verification
â”‚   â”œâ”€â”€ test_data_loading.py   # Data tests
â”‚   â”œâ”€â”€ test_models.py         # Model tests
â”‚   â””â”€â”€ test_integration.py    # Integration tests
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup.py               # One-time setup
â”‚   â”œâ”€â”€ download_data.py       # Dataset download
â”‚   â””â”€â”€ run_training.py        # Training launcher
â””â”€â”€ requirements.txt           # Dependencies
```

## ğŸ§ª Testing

All components include empirical tests:

- **test_setup.py**: Verify Modal connection, volumes, GPU
- **test_data_loading.py**: Validate data integrity and formats
- **test_models.py**: Test model architectures and GPU utilization
- **test_integration.py**: End-to-end pipeline validation

Run all tests:
```bash
python tests/test_setup.py
python tests/test_data_loading.py
python tests/test_models.py
python tests/test_integration.py
```

## ğŸ“ˆ Expected Performance

| Model | Metric | Expected Value |
|-------|--------|----------------|
| Anomaly Detection | F1-Score | 0.85-0.88 |
| Anomaly Detection | False Positive Rate | <5% |
| Predictive Maintenance | MAE (Temperature) | <2.5Â°C |
| Predictive Maintenance | Prediction Horizon | 15-20 min |

## ğŸ”§ Configuration

Edit `modal/config.py` to customize:
- GPU type (A100, H100, etc.)
- Model hyperparameters
- Volume sizes
- Dataset sources

## ğŸ“ License

MIT License - See LICENSE file

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Run tests: `python tests/`
4. Submit pull request

## ğŸ“ Support

For issues and questions:
- Check tests: `python tests/test_setup.py`
- Review logs: `modal logs`
- Open an issue on GitHub

## ğŸ¯ Roadmap

- [x] Phase 1: Infrastructure (Current)
- [ ] Phase 2: Data Pipeline
- [ ] Phase 3: Model Training
- [ ] Phase 4: Testing & Optimization
- [ ] Phase 5: Deployment

---

**Built with Modal.com** â˜ï¸ğŸš€
